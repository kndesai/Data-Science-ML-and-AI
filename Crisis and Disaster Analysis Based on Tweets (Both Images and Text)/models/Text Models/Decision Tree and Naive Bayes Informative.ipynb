{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7dfce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             event_name            tweet_id              image_id  \\\n",
      "0  california_wildfires  917791291823591425  917791291823591425_0   \n",
      "1  california_wildfires  917793137925459968  917793137925459968_0   \n",
      "2  california_wildfires  917793137925459968  917793137925459968_1   \n",
      "3  california_wildfires  917793137925459968  917793137925459968_2   \n",
      "4  california_wildfires  917815040962695168  917815040962695168_0   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
      "1  RT @KAKEnews: California wildfires destroy mor...   \n",
      "2  RT @KAKEnews: California wildfires destroy mor...   \n",
      "3  RT @KAKEnews: California wildfires destroy mor...   \n",
      "4  RT @TheAtlantic: Photos of California's destru...   \n",
      "\n",
      "                                               image        label  \\\n",
      "0  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "1  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "2  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "3  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "4  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "\n",
      "    label_text  label_image label_text_image  \n",
      "0  informative  informative         Positive  \n",
      "1  informative  informative         Positive  \n",
      "2  informative  informative         Positive  \n",
      "3  informative  informative         Positive  \n",
      "4  informative  informative         Positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the TSV file into a DataFrame\n",
    "df = pd.read_csv('task_informative_text_img_agreed_lab_train.tsv', sep='\\t')\n",
    "\n",
    "# display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbe82e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informative        6345\n",
      "not_informative    3256\n",
      "Name: label_text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the count of different types of entries in a column\n",
    "counts = df['label_text'].value_counts()\n",
    "\n",
    "# display the counts\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393baf43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['event_name', 'tweet_id', 'image_id', 'image', 'label', 'label_image', 'label_text_image'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevent_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweet_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_text_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# display the updated DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['event_name', 'tweet_id', 'image_id', 'image', 'label', 'label_image', 'label_text_image'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop(['event_name', 'tweet_id', 'image_id', 'image', 'label', 'label_image', 'label_text_image'], axis=1)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b476ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text   label_text  \\\n",
      "0  rt @cal_oes: pls share: weâ€™re capturing wild...  informative   \n",
      "1  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "2  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "3  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "4  rt @theatlantic: photos of california's destru...  informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  rt cal_oes pls share weâre capturing wildfire ...  \n",
      "1  rt kakenews california wildfires destroy more ...  \n",
      "2  rt kakenews california wildfires destroy more ...  \n",
      "3  rt kakenews california wildfires destroy more ...  \n",
      "4  rt theatlantic photos of californias destructi...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# define a lambda function to preprocess a single tweet\n",
    "preprocess_tweet = lambda tweet: re.sub(r'#\\w+\\s*|https?:\\/\\/.*\\/\\w*|[^\\w\\s]', '', tweet)\n",
    "\n",
    "# apply the preprocessing function to the relevant columns of the DataFrame\n",
    "df['processed_text'] = df['tweet_text'].apply(preprocess_tweet)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c882cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text   label_text  \\\n",
      "0  rt @cal_oes: pls share: weâ€™re capturing wild...  informative   \n",
      "1  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "2  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "3  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "4  rt @theatlantic: photos of california's destru...  informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  rt cal_oes pls share weâre capturing wildfire ...  \n",
      "1  rt kakenews california wildfires destroy more ...  \n",
      "2  rt kakenews california wildfires destroy more ...  \n",
      "3  rt kakenews california wildfires destroy more ...  \n",
      "4  rt theatlantic photos of californias destructi...  \n"
     ]
    }
   ],
   "source": [
    "# convert all text in the DataFrame to lowercase\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f94adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        event_name            tweet_id              image_id  \\\n",
      "0  srilanka_floods  878185882431389696  878185882431389696_0   \n",
      "1  hurricane_maria  910542719864397824  910542719864397824_0   \n",
      "2  hurricane_maria  913009824195104768  913009824195104768_0   \n",
      "3  hurricane_maria  916053383383011328  916053383383011328_0   \n",
      "4  hurricane_maria  922230253359116288  922230253359116288_0   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  Cristofer CLEMENTE MORA now in 2nd at aguille ...   \n",
      "1  Hurricane Maria batters Puerto Rico as a Cat 4...   \n",
      "2  8am #Maria update: holding steady as a strong ...   \n",
      "3  .@lprnyc is hosting a Puerto Rico benefict con...   \n",
      "4  Vet In Puerto Rico Hurricane Worse Than War - ...   \n",
      "\n",
      "                                               image            label  \\\n",
      "0  data_image/srilanka_floods/23_6_2017/878185882...  not_informative   \n",
      "1  data_image/hurricane_maria/20_9_2017/910542719...      informative   \n",
      "2  data_image/hurricane_maria/27_9_2017/913009824...      informative   \n",
      "3  data_image/hurricane_maria/5_10_2017/916053383...      informative   \n",
      "4  data_image/hurricane_maria/22_10_2017/92223025...  not_informative   \n",
      "\n",
      "        label_text      label_image label_text_image  \n",
      "0  not_informative  not_informative         Positive  \n",
      "1      informative      informative         Positive  \n",
      "2      informative      informative         Positive  \n",
      "3      informative      informative         Positive  \n",
      "4  not_informative  not_informative         Positive  \n"
     ]
    }
   ],
   "source": [
    "# read the TSV file into a DataFrame\n",
    "ds = pd.read_csv('task_informative_text_img_agreed_lab_test.tsv', sep='\\t')\n",
    "\n",
    "# display the first few rows of the DataFrame\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6414afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text       label_text\n",
      "0  Cristofer CLEMENTE MORA now in 2nd at aguille ...  not_informative\n",
      "1  Hurricane Maria batters Puerto Rico as a Cat 4...      informative\n",
      "2  8am #Maria update: holding steady as a strong ...      informative\n",
      "3  .@lprnyc is hosting a Puerto Rico benefict con...      informative\n",
      "4  Vet In Puerto Rico Hurricane Worse Than War - ...  not_informative\n"
     ]
    }
   ],
   "source": [
    "ds = ds.drop(['event_name', 'tweet_id', 'image_id', 'image', 'label', 'label_image', 'label_text_image'], axis=1)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2afe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text       label_text  \\\n",
      "0  Cristofer CLEMENTE MORA now in 2nd at aguille ...  not_informative   \n",
      "1  Hurricane Maria batters Puerto Rico as a Cat 4...      informative   \n",
      "2  8am #Maria update: holding steady as a strong ...      informative   \n",
      "3  .@lprnyc is hosting a Puerto Rico benefict con...      informative   \n",
      "4  Vet In Puerto Rico Hurricane Worse Than War - ...  not_informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  Cristofer CLEMENTE MORA now in 2nd at aguille ...  \n",
      "1  Hurricane Maria batters Puerto Rico as a Cat 4...  \n",
      "2  8am update holding steady as a strong tropical...  \n",
      "3  lprnyc is hosting a Puerto Rico benefict conce...  \n",
      "4  Vet In Puerto Rico Hurricane Worse Than War  S...  \n"
     ]
    }
   ],
   "source": [
    "# apply the preprocessing function to the relevant columns of the DataFrame\n",
    "ds['processed_text'] = ds['tweet_text'].apply(preprocess_tweet)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc477a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text       label_text  \\\n",
      "0  cristofer clemente mora now in 2nd at aguille ...  not_informative   \n",
      "1  hurricane maria batters puerto rico as a cat 4...      informative   \n",
      "2  8am #maria update: holding steady as a strong ...      informative   \n",
      "3  .@lprnyc is hosting a puerto rico benefict con...      informative   \n",
      "4  vet in puerto rico hurricane worse than war - ...  not_informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  cristofer clemente mora now in 2nd at aguille ...  \n",
      "1  hurricane maria batters puerto rico as a cat 4...  \n",
      "2  8am update holding steady as a strong tropical...  \n",
      "3  lprnyc is hosting a puerto rico benefict conce...  \n",
      "4  vet in puerto rico hurricane worse than war  s...  \n"
     ]
    }
   ],
   "source": [
    "# convert all text in the DataFrame to lowercase\n",
    "ds = ds.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff4991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text        9601\n",
       "label_text        9601\n",
       "processed_text    9601\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c4cbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text        1534\n",
       "label_text        1534\n",
       "processed_text    1534\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a640cfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text        11135\n",
       "label_text        11135\n",
       "processed_text    11135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df,ds])\n",
    "df_concat.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2099135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a CountVectorizer object to convert the preprocessed text into a numerical feature vector\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# convert the preprocessed text into a numerical feature vector\n",
    "X = vectorizer.fit_transform(df_concat['processed_text'])\n",
    "\n",
    "# use the 'label_text' column as the labels\n",
    "y = df_concat['label_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7302e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f30d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DecisionTreeClassifier object and fit it to the training data\n",
    "clf1 = DecisionTreeClassifier(random_state=42)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d06d224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8046699595868881\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the decision tree on the testing data\n",
    "accuracy = clf1.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0532b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8004\n",
      "Recall: 0.8047\n",
      "F1 score: 0.8010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "# calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a2a3407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efa5c2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8504714863044455\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the naive-bayes on the testing data\n",
    "accuracy = clf2.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35f5f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8505\n",
      "Recall: 0.8505\n",
      "F1 score: 0.8448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "# calculate precision, recall, and F1 score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "286f0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['informative']\n"
     ]
    }
   ],
   "source": [
    "tweet = '40 dead and 300 injured in a hurricane'\n",
    "tweet_vec = vectorizer.transform([tweet])\n",
    "label = clf1.predict(tweet_vec)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d14e6628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_informative']\n"
     ]
    }
   ],
   "source": [
    "tweet = 'This is nothing'\n",
    "tweet_vec = vectorizer.transform([tweet])\n",
    "label = clf2.predict(tweet_vec)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3295cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_informative']\n"
     ]
    }
   ],
   "source": [
    "tweet = 'Peaky Blinders is my favourite show.'\n",
    "tweet_vec = vectorizer.transform([tweet])\n",
    "label = clf1.predict(tweet_vec)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c656fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['informative']\n"
     ]
    }
   ],
   "source": [
    "tweet = 'Hurricane approaching Florida next'\n",
    "tweet_vec = vectorizer.transform([tweet])\n",
    "label = clf2.predict(tweet_vec)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
