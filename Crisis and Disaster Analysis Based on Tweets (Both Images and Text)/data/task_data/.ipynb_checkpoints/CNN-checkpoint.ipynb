{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8e2182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             event_name            tweet_id              image_id  \\\n",
      "0  california_wildfires  917791291823591425  917791291823591425_0   \n",
      "1  california_wildfires  917793137925459968  917793137925459968_0   \n",
      "2  california_wildfires  917793137925459968  917793137925459968_1   \n",
      "3  california_wildfires  917793137925459968  917793137925459968_2   \n",
      "4  california_wildfires  917815040962695168  917815040962695168_0   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
      "1  RT @KAKEnews: California wildfires destroy mor...   \n",
      "2  RT @KAKEnews: California wildfires destroy mor...   \n",
      "3  RT @KAKEnews: California wildfires destroy mor...   \n",
      "4  RT @TheAtlantic: Photos of California's destru...   \n",
      "\n",
      "                                               image        label  \\\n",
      "0  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "1  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "2  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "3  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "4  data_image/california_wildfires/10_10_2017/917...  informative   \n",
      "\n",
      "    label_text  label_image label_text_image  \n",
      "0  informative  informative         Positive  \n",
      "1  informative  informative         Positive  \n",
      "2  informative  informative         Positive  \n",
      "3  informative  informative         Positive  \n",
      "4  informative  informative         Positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the TSV file into a DataFrame\n",
    "df = pd.read_csv('task_informative_text_img_agreed_lab_train.tsv', sep='\\t')\n",
    "\n",
    "# display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5ca6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        event_name            tweet_id              image_id  \\\n",
      "0  srilanka_floods  878185882431389696  878185882431389696_0   \n",
      "1  hurricane_maria  910542719864397824  910542719864397824_0   \n",
      "2  hurricane_maria  913009824195104768  913009824195104768_0   \n",
      "3  hurricane_maria  916053383383011328  916053383383011328_0   \n",
      "4  hurricane_maria  922230253359116288  922230253359116288_0   \n",
      "\n",
      "                                          tweet_text  \\\n",
      "0  Cristofer CLEMENTE MORA now in 2nd at aguille ...   \n",
      "1  Hurricane Maria batters Puerto Rico as a Cat 4...   \n",
      "2  8am #Maria update: holding steady as a strong ...   \n",
      "3  .@lprnyc is hosting a Puerto Rico benefict con...   \n",
      "4  Vet In Puerto Rico Hurricane Worse Than War - ...   \n",
      "\n",
      "                                               image            label  \\\n",
      "0  data_image/srilanka_floods/23_6_2017/878185882...  not_informative   \n",
      "1  data_image/hurricane_maria/20_9_2017/910542719...      informative   \n",
      "2  data_image/hurricane_maria/27_9_2017/913009824...      informative   \n",
      "3  data_image/hurricane_maria/5_10_2017/916053383...      informative   \n",
      "4  data_image/hurricane_maria/22_10_2017/92223025...  not_informative   \n",
      "\n",
      "        label_text      label_image label_text_image  \n",
      "0  not_informative  not_informative         Positive  \n",
      "1      informative      informative         Positive  \n",
      "2      informative      informative         Positive  \n",
      "3      informative      informative         Positive  \n",
      "4  not_informative  not_informative         Positive  \n"
     ]
    }
   ],
   "source": [
    "# read the TSV file into a DataFrame\n",
    "ds = pd.read_csv('task_informative_text_img_agreed_lab_test.tsv', sep='\\t')\n",
    "\n",
    "# display the first few rows of the DataFrame\n",
    "print(ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f133ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_name          11135\n",
       "tweet_id            11135\n",
       "image_id            11135\n",
       "tweet_text          11135\n",
       "image               11135\n",
       "label               11135\n",
       "label_text          11135\n",
       "label_image         11135\n",
       "label_text_image    11135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,ds])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80962e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text   label_text\n",
      "0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...  informative\n",
      "1  RT @KAKEnews: California wildfires destroy mor...  informative\n",
      "2  RT @KAKEnews: California wildfires destroy mor...  informative\n",
      "3  RT @KAKEnews: California wildfires destroy mor...  informative\n",
      "4  RT @TheAtlantic: Photos of California's destru...  informative\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['event_name', 'tweet_id', 'image_id', 'image', 'label', 'label_image', 'label_text_image'], axis=1)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06a3382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text   label_text  \\\n",
      "0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...  informative   \n",
      "1  RT @KAKEnews: California wildfires destroy mor...  informative   \n",
      "2  RT @KAKEnews: California wildfires destroy mor...  informative   \n",
      "3  RT @KAKEnews: California wildfires destroy mor...  informative   \n",
      "4  RT @TheAtlantic: Photos of California's destru...  informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  RT Cal_OES PLS SHARE Weâre capturing wildfire ...  \n",
      "1  RT KAKEnews California wildfires destroy more ...  \n",
      "2  RT KAKEnews California wildfires destroy more ...  \n",
      "3  RT KAKEnews California wildfires destroy more ...  \n",
      "4  RT TheAtlantic Photos of Californias destructi...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# define a lambda function to preprocess a single tweet\n",
    "preprocess_tweet = lambda tweet: re.sub(r'#\\w+\\s*|https?:\\/\\/.*\\/\\w*|[^\\w\\s]', '', tweet)\n",
    "\n",
    "# apply the preprocessing function to the relevant columns of the DataFrame\n",
    "df['processed_text'] = df['tweet_text'].apply(preprocess_tweet)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c337803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text   label_text  \\\n",
      "0  rt @cal_oes: pls share: weâ€™re capturing wild...  informative   \n",
      "1  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "2  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "3  rt @kakenews: california wildfires destroy mor...  informative   \n",
      "4  rt @theatlantic: photos of california's destru...  informative   \n",
      "\n",
      "                                      processed_text  \n",
      "0  rt cal_oes pls share weâre capturing wildfire ...  \n",
      "1  rt kakenews california wildfires destroy more ...  \n",
      "2  rt kakenews california wildfires destroy more ...  \n",
      "3  rt kakenews california wildfires destroy more ...  \n",
      "4  rt theatlantic photos of californias destructi...  \n"
     ]
    }
   ],
   "source": [
    "# convert all text in the DataFrame to lowercase\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "# display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a70185de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ff6224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df['label_text'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427a7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f281b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_len = max([len(x) for x in X_train])\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3715738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eaf329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'mean_squared_error/Cast' defined at (most recent call last):\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_14992\\97561900.py\", line 2, in <module>\n      model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1469, in mean_squared_error\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'mean_squared_error/Cast'\nCast string to float is not supported\n\t [[{{node mean_squared_error/Cast}}]] [Op:__inference_train_function_6227]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'mean_squared_error/Cast' defined at (most recent call last):\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_14992\\97561900.py\", line 2, in <module>\n      model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1469, in mean_squared_error\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'mean_squared_error/Cast'\nCast string to float is not supported\n\t [[{{node mean_squared_error/Cast}}]] [Op:__inference_train_function_6227]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50354134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
