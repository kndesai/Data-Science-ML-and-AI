{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kaust\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    print(\"Data successfully loaded!\")\n",
    "\n",
    "    return  X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        # input layer\n",
    "        keras.layers.Flatten(input_shape=(X.shape[1], X.shape[2])),\n",
    "\n",
    "        # 1st dense layer\n",
    "        keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # 2nd dense layer\n",
    "        keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # 3rd dense layer\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "\n",
    "        # output layer\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 1690)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               865792    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1014218 (3.87 MB)\n",
      "Trainable params: 1014218 (3.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 9s 24ms/step - loss: 23.5018 - accuracy: 0.1659 - val_loss: 3.7581 - val_accuracy: 0.2823\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 6.6408 - accuracy: 0.1897 - val_loss: 3.3147 - val_accuracy: 0.2733\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 4.6484 - accuracy: 0.1945 - val_loss: 3.2869 - val_accuracy: 0.2648\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 3.9442 - accuracy: 0.2091 - val_loss: 3.2405 - val_accuracy: 0.2943\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.6380 - accuracy: 0.2173 - val_loss: 3.2429 - val_accuracy: 0.2993\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 3.5106 - accuracy: 0.2377 - val_loss: 3.1693 - val_accuracy: 0.3208\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.4149 - accuracy: 0.2508 - val_loss: 3.2019 - val_accuracy: 0.3133\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.3348 - accuracy: 0.2664 - val_loss: 3.1514 - val_accuracy: 0.3183\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.2958 - accuracy: 0.2700 - val_loss: 3.0700 - val_accuracy: 0.3468\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.2373 - accuracy: 0.2812 - val_loss: 3.0636 - val_accuracy: 0.3544\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.2261 - accuracy: 0.2903 - val_loss: 3.0287 - val_accuracy: 0.3514\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.1660 - accuracy: 0.2999 - val_loss: 3.0234 - val_accuracy: 0.3534\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.1467 - accuracy: 0.3035 - val_loss: 2.9738 - val_accuracy: 0.3674\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 3.1020 - accuracy: 0.3138 - val_loss: 2.9463 - val_accuracy: 0.3684\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 3.0519 - accuracy: 0.3207 - val_loss: 2.8972 - val_accuracy: 0.3774\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 3.0153 - accuracy: 0.3252 - val_loss: 2.8713 - val_accuracy: 0.4004\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 2.9977 - accuracy: 0.3365 - val_loss: 2.8495 - val_accuracy: 0.4049\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 2.9497 - accuracy: 0.3499 - val_loss: 2.8236 - val_accuracy: 0.4179\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.9151 - accuracy: 0.3559 - val_loss: 2.7801 - val_accuracy: 0.4049\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.8808 - accuracy: 0.3622 - val_loss: 2.7373 - val_accuracy: 0.4309\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 2.8424 - accuracy: 0.3674 - val_loss: 2.7184 - val_accuracy: 0.4109\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 2.7891 - accuracy: 0.3757 - val_loss: 2.6772 - val_accuracy: 0.4199\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 2.7583 - accuracy: 0.3759 - val_loss: 2.6387 - val_accuracy: 0.4299\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 2.7163 - accuracy: 0.3933 - val_loss: 2.6284 - val_accuracy: 0.4354\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.6774 - accuracy: 0.3982 - val_loss: 2.5632 - val_accuracy: 0.4615\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.6290 - accuracy: 0.4019 - val_loss: 2.5387 - val_accuracy: 0.4484\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.6024 - accuracy: 0.4194 - val_loss: 2.4755 - val_accuracy: 0.4585\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.5477 - accuracy: 0.4259 - val_loss: 2.4909 - val_accuracy: 0.4570\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.5297 - accuracy: 0.4221 - val_loss: 2.4447 - val_accuracy: 0.4705\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 2.4744 - accuracy: 0.4367 - val_loss: 2.4105 - val_accuracy: 0.4655\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.4283 - accuracy: 0.4490 - val_loss: 2.3923 - val_accuracy: 0.4850\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 2.3927 - accuracy: 0.4531 - val_loss: 2.3563 - val_accuracy: 0.4845\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 2.3548 - accuracy: 0.4569 - val_loss: 2.2780 - val_accuracy: 0.4855\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 2.3250 - accuracy: 0.4591 - val_loss: 2.2728 - val_accuracy: 0.4870\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 2.2716 - accuracy: 0.4677 - val_loss: 2.2362 - val_accuracy: 0.4985\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 2.2431 - accuracy: 0.4747 - val_loss: 2.2000 - val_accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 2.1892 - accuracy: 0.4821 - val_loss: 2.2102 - val_accuracy: 0.5090\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 2.1563 - accuracy: 0.4870 - val_loss: 2.1832 - val_accuracy: 0.4935\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 2.1301 - accuracy: 0.4957 - val_loss: 2.1256 - val_accuracy: 0.5050\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 2.0604 - accuracy: 0.5094 - val_loss: 2.0839 - val_accuracy: 0.5065\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 2.0624 - accuracy: 0.5055 - val_loss: 2.0604 - val_accuracy: 0.5070\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.9988 - accuracy: 0.5173 - val_loss: 2.0352 - val_accuracy: 0.5130\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.9789 - accuracy: 0.5165 - val_loss: 2.0696 - val_accuracy: 0.5165\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.9493 - accuracy: 0.5244 - val_loss: 2.0651 - val_accuracy: 0.5130\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.9209 - accuracy: 0.5275 - val_loss: 2.0057 - val_accuracy: 0.5370\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.8888 - accuracy: 0.5341 - val_loss: 1.9751 - val_accuracy: 0.5235\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.8588 - accuracy: 0.5346 - val_loss: 1.9749 - val_accuracy: 0.5360\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.8228 - accuracy: 0.5511 - val_loss: 1.9127 - val_accuracy: 0.5390\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.7887 - accuracy: 0.5503 - val_loss: 1.9410 - val_accuracy: 0.5275\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.7462 - accuracy: 0.5730 - val_loss: 1.9296 - val_accuracy: 0.5385\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.7401 - accuracy: 0.5585 - val_loss: 1.8669 - val_accuracy: 0.5465\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.7089 - accuracy: 0.5645 - val_loss: 1.8799 - val_accuracy: 0.5521\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6912 - accuracy: 0.5714 - val_loss: 1.9171 - val_accuracy: 0.5425\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6646 - accuracy: 0.5829 - val_loss: 1.8298 - val_accuracy: 0.5480\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6518 - accuracy: 0.5846 - val_loss: 1.8479 - val_accuracy: 0.5395\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.6090 - accuracy: 0.5941 - val_loss: 1.8551 - val_accuracy: 0.5561\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5820 - accuracy: 0.5994 - val_loss: 1.8147 - val_accuracy: 0.5516\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5760 - accuracy: 0.6002 - val_loss: 1.7987 - val_accuracy: 0.5811\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5597 - accuracy: 0.5985 - val_loss: 1.7743 - val_accuracy: 0.5606\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.5292 - accuracy: 0.6123 - val_loss: 1.7892 - val_accuracy: 0.5646\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.5064 - accuracy: 0.6209 - val_loss: 1.7523 - val_accuracy: 0.5606\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.4915 - accuracy: 0.6219 - val_loss: 1.8152 - val_accuracy: 0.5706\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.4510 - accuracy: 0.6317 - val_loss: 1.7127 - val_accuracy: 0.5916\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.4465 - accuracy: 0.6303 - val_loss: 1.7855 - val_accuracy: 0.5576\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.4345 - accuracy: 0.6338 - val_loss: 1.7353 - val_accuracy: 0.5696\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.4209 - accuracy: 0.6390 - val_loss: 1.7982 - val_accuracy: 0.5571\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.4093 - accuracy: 0.6420 - val_loss: 1.7213 - val_accuracy: 0.5771\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.4030 - accuracy: 0.6411 - val_loss: 1.7759 - val_accuracy: 0.5696\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.3783 - accuracy: 0.6458 - val_loss: 1.7553 - val_accuracy: 0.5806\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.3462 - accuracy: 0.6541 - val_loss: 1.7565 - val_accuracy: 0.5816\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.3285 - accuracy: 0.6610 - val_loss: 1.7457 - val_accuracy: 0.5691\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.3307 - accuracy: 0.6592 - val_loss: 1.7942 - val_accuracy: 0.5846\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.3196 - accuracy: 0.6647 - val_loss: 1.7681 - val_accuracy: 0.5851\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.2802 - accuracy: 0.6745 - val_loss: 1.7255 - val_accuracy: 0.5876\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.2761 - accuracy: 0.6738 - val_loss: 1.7091 - val_accuracy: 0.5906\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.2420 - accuracy: 0.6824 - val_loss: 1.7275 - val_accuracy: 0.5861\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.2540 - accuracy: 0.6825 - val_loss: 1.8174 - val_accuracy: 0.5846\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.2329 - accuracy: 0.6828 - val_loss: 1.7250 - val_accuracy: 0.5881\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.2186 - accuracy: 0.6899 - val_loss: 1.7616 - val_accuracy: 0.5826\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.2174 - accuracy: 0.6913 - val_loss: 1.7454 - val_accuracy: 0.5876\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.2117 - accuracy: 0.6930 - val_loss: 1.6837 - val_accuracy: 0.5956\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.1968 - accuracy: 0.6938 - val_loss: 1.7783 - val_accuracy: 0.5921\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.1681 - accuracy: 0.7053 - val_loss: 1.7192 - val_accuracy: 0.6081\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.1449 - accuracy: 0.7091 - val_loss: 1.7987 - val_accuracy: 0.5811\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.1538 - accuracy: 0.7032 - val_loss: 1.8577 - val_accuracy: 0.5876\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.1227 - accuracy: 0.7183 - val_loss: 1.8035 - val_accuracy: 0.5846\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.1499 - accuracy: 0.7073 - val_loss: 1.7639 - val_accuracy: 0.5896\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.1195 - accuracy: 0.7159 - val_loss: 1.7506 - val_accuracy: 0.6021\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.0983 - accuracy: 0.7223 - val_loss: 1.8055 - val_accuracy: 0.5911\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.1329 - accuracy: 0.7153 - val_loss: 1.7205 - val_accuracy: 0.6001\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.0985 - accuracy: 0.7252 - val_loss: 1.8024 - val_accuracy: 0.6016\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.0600 - accuracy: 0.7312 - val_loss: 1.7260 - val_accuracy: 0.5996\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.0749 - accuracy: 0.7361 - val_loss: 1.8147 - val_accuracy: 0.5931\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.0635 - accuracy: 0.7341 - val_loss: 1.6669 - val_accuracy: 0.5941\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.0630 - accuracy: 0.7321 - val_loss: 1.7662 - val_accuracy: 0.6016\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 5s 18ms/step - loss: 1.0395 - accuracy: 0.7452 - val_loss: 1.7117 - val_accuracy: 0.6091\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 1.0305 - accuracy: 0.7419 - val_loss: 1.7808 - val_accuracy: 0.5931\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 1.0231 - accuracy: 0.7466 - val_loss: 1.7688 - val_accuracy: 0.6126\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 5s 19ms/step - loss: 1.0114 - accuracy: 0.7470 - val_loss: 1.7768 - val_accuracy: 0.5936\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 1.0045 - accuracy: 0.7490 - val_loss: 1.7547 - val_accuracy: 0.6031\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "X_new, y_new = load_data(\"data_10.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-2.42435989e+02,  1.02184860e+02, -9.91323471e+00, ...,\n",
       "          -3.95323515e+00, -2.40564585e+00, -2.38090467e+00],\n",
       "         [-2.12989746e+02,  1.03544777e+02, -1.08341722e+01, ...,\n",
       "          -5.81353188e+00,  2.64356732e+00, -2.80662131e+00],\n",
       "         [-1.95409332e+02,  1.04360657e+02, -1.85501546e-01, ...,\n",
       "          -1.08171635e+01, -5.88805735e-01, -5.28410530e+00],\n",
       "         ...,\n",
       "         [-1.24157700e+02,  6.37352219e+01,  2.11729393e+01, ...,\n",
       "          -1.65676632e+01,  1.37965145e+01, -2.31835365e+01],\n",
       "         [-1.11283928e+02,  6.05447197e+01,  1.33710289e+00, ...,\n",
       "          -1.22842140e+01,  1.48256054e+01, -1.58052368e+01],\n",
       "         [-1.31811951e+02,  6.65644531e+01, -7.93185806e+00, ...,\n",
       "          -8.66252232e+00,  1.16732769e+01, -8.72385597e+00]],\n",
       " \n",
       "        [[-1.71760757e+02,  8.67187042e+01, -1.29779549e+01, ...,\n",
       "          -7.98365927e+00,  3.68273449e+00, -4.20823479e+00],\n",
       "         [-1.53283447e+02,  9.38014526e+01, -2.03874569e+01, ...,\n",
       "          -7.75853252e+00,  8.76973343e+00, -9.67060661e+00],\n",
       "         [-1.64260010e+02,  9.80545425e+01, -2.59105644e+01, ...,\n",
       "          -6.87140751e+00,  1.37144985e+01, -7.40781355e+00],\n",
       "         ...,\n",
       "         [-1.92144089e+02,  1.12161606e+02, -1.85086098e+01, ...,\n",
       "          -5.79698086e+00,  1.01001530e+01, -5.63120651e+00],\n",
       "         [-1.36761780e+02,  1.17895721e+02, -6.85177851e+00, ...,\n",
       "          -7.53184175e+00,  1.16150856e+01, -6.23139501e-01],\n",
       "         [-1.19226776e+02,  1.15008316e+02,  4.01943064e+00, ...,\n",
       "          -1.17355061e+01,  1.06826344e+01,  3.05238056e+00]],\n",
       " \n",
       "        [[-1.29166855e+02,  1.07058235e+02, -7.27768707e+00, ...,\n",
       "          -3.58296037e+00,  9.42733955e+00,  4.78677082e+00],\n",
       "         [-1.20053070e+02,  1.13288795e+02, -9.96273136e+00, ...,\n",
       "          -6.17033863e+00,  8.41439819e+00, -3.55640292e-01],\n",
       "         [-1.50047852e+02,  1.24548141e+02, -6.92227364e+00, ...,\n",
       "          -1.00242748e+01,  7.37714767e+00, -6.65175247e+00],\n",
       "         ...,\n",
       "         [-8.82240601e+01,  1.35415100e+02, -1.79079971e+01, ...,\n",
       "          -1.87740784e+01,  1.43474998e+01,  5.09636879e+00],\n",
       "         [-9.76525726e+01,  1.31318161e+02, -1.36036673e+01, ...,\n",
       "          -1.30186520e+01,  3.22227931e+00,  9.21608257e+00],\n",
       "         [-9.25691833e+01,  1.33885040e+02, -9.84093857e+00, ...,\n",
       "          -6.46690083e+00,  3.52999091e-01,  1.65853519e+01]],\n",
       " \n",
       "        [[-1.07022514e+02,  1.25826569e+02, -1.26175575e+01, ...,\n",
       "          -2.65564966e+00,  3.65327930e+00,  1.53774586e+01],\n",
       "         [-1.07521790e+02,  1.31931335e+02, -1.50151396e+01, ...,\n",
       "          -5.26023626e+00,  3.05318880e+00,  1.50423622e+01],\n",
       "         [-1.22522499e+02,  1.32053162e+02, -3.62047501e+01, ...,\n",
       "          -2.05188484e+01,  5.51695108e+00,  9.00404263e+00],\n",
       "         ...,\n",
       "         [-1.08939369e+02,  1.46131653e+02, -2.78947582e+01, ...,\n",
       "          -3.63439178e+00,  8.78615952e+00, -2.33571768e+00],\n",
       "         [-1.05611084e+02,  1.39955124e+02, -2.27368164e+01, ...,\n",
       "           3.04758573e+00,  2.62182331e+00, -1.44969606e+00],\n",
       "         [-1.11266403e+02,  1.32468903e+02, -7.11733913e+00, ...,\n",
       "           1.11230268e+01,  4.45508480e+00, -2.69149005e-01]],\n",
       " \n",
       "        [[-1.24805534e+02,  1.34353424e+02,  1.06810367e+00, ...,\n",
       "           7.83862114e-01, -6.71632576e+00, -7.77959919e+00],\n",
       "         [-1.12895615e+02,  1.41554642e+02, -1.18320713e+01, ...,\n",
       "          -1.43625269e+01, -9.56646824e+00, -9.47410965e+00],\n",
       "         [-1.31466537e+02,  1.58192017e+02, -1.33676195e+01, ...,\n",
       "          -2.15271835e+01, -3.86884451e+00, -1.16394138e+01],\n",
       "         ...,\n",
       "         [-1.65736237e+02,  1.57052795e+02, -3.97764893e+01, ...,\n",
       "           7.16179013e-01,  1.70662212e+01,  2.99718094e+00],\n",
       "         [-1.39201782e+02,  1.47723083e+02, -4.03237457e+01, ...,\n",
       "           8.45654488e+00,  1.59196854e+01,  7.16439724e+00],\n",
       "         [-1.25530319e+02,  1.32349609e+02, -3.47694550e+01, ...,\n",
       "           1.61968613e+01,  1.71209946e+01,  9.30861664e+00]]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[:5], y_new[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre for the Song: blues\n"
     ]
    }
   ],
   "source": [
    "mapping = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "aggregated_predictions = np.max(predictions, axis=0)\n",
    "predicted_genre_index = np.argmax(aggregated_predictions)\n",
    "predicted_genre = mapping[predicted_genre_index]\n",
    "print(f\"Predicted Genre for the Song: {predicted_genre}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
